{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the pre-processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-processed data\n",
    "features_normalized = np.load('Pre_Processed_Data/features_normalized.npy')\n",
    "labels = np.load('Pre_Processed_Data/labels.npy')\n",
    "\n",
    "# Convert the data to PyTorch tensors\n",
    "features_normalized = torch.tensor(features_normalized).float()\n",
    "labels = torch.tensor(labels).long()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a custom dataset and create a DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom dataset\n",
    "class ParkinsonsDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]\n",
    "\n",
    "# Create a DataLoader\n",
    "dataset = ParkinsonsDataset(features_normalized, labels)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(features_normalized.shape[1], 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the neural network\n",
    "net = Net()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the loss function and the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function and the optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: 0.6218272021838597\n",
      "Epoch: 1 Loss: 0.550872415304184\n",
      "Epoch: 2 Loss: 0.5397496223449707\n",
      "Epoch: 3 Loss: 0.5125875515597207\n",
      "Epoch: 4 Loss: 0.4295012003609112\n",
      "Epoch: 5 Loss: 0.4203262392963682\n",
      "Epoch: 6 Loss: 0.4359692462853023\n",
      "Epoch: 7 Loss: 0.4298115244933537\n",
      "Epoch: 8 Loss: 0.4244547826903207\n",
      "Epoch: 9 Loss: 0.4579229269708906\n",
      "Epoch: 10 Loss: 0.3723395892551967\n",
      "Epoch: 11 Loss: 0.359037663255419\n",
      "Epoch: 12 Loss: 0.3802281107221331\n",
      "Epoch: 13 Loss: 0.3361007102898189\n",
      "Epoch: 14 Loss: 0.31338574843747274\n",
      "Epoch: 15 Loss: 0.3629936490740095\n",
      "Epoch: 16 Loss: 0.30719466294561115\n",
      "Epoch: 17 Loss: 0.36636551150253843\n",
      "Epoch: 18 Loss: 0.3873536842209952\n",
      "Epoch: 19 Loss: 0.3134868230138506\n",
      "Epoch: 20 Loss: 0.3539097649710519\n",
      "Epoch: 21 Loss: 0.29480829409190584\n",
      "Epoch: 22 Loss: 0.3107388360159738\n",
      "Epoch: 23 Loss: 0.26916430411594255\n",
      "Epoch: 24 Loss: 0.33015501712049755\n",
      "Epoch: 25 Loss: 0.3118360298020499\n",
      "Epoch: 26 Loss: 0.2687418503420694\n",
      "Epoch: 27 Loss: 0.2699644608157022\n",
      "Epoch: 28 Loss: 0.2486508418140667\n",
      "Epoch: 29 Loss: 0.2636889432157789\n",
      "Epoch: 30 Loss: 0.2922018808977945\n",
      "Epoch: 31 Loss: 0.23446863889694214\n",
      "Epoch: 32 Loss: 0.3194989711046219\n",
      "Epoch: 33 Loss: 0.261794381908008\n",
      "Epoch: 34 Loss: 0.30951022250311716\n",
      "Epoch: 35 Loss: 0.23931950330734253\n",
      "Epoch: 36 Loss: 0.23236863235277788\n",
      "Epoch: 37 Loss: 0.22114960051008634\n",
      "Epoch: 38 Loss: 0.27421956828662325\n",
      "Epoch: 39 Loss: 0.2930345961025783\n",
      "Epoch: 40 Loss: 0.21923988738230296\n",
      "Epoch: 41 Loss: 0.2100797758570739\n",
      "Epoch: 42 Loss: 0.20468824596277305\n",
      "Epoch: 43 Loss: 0.21970897700105393\n",
      "Epoch: 44 Loss: 0.21003163818802154\n",
      "Epoch: 45 Loss: 0.20970373813595092\n",
      "Epoch: 46 Loss: 0.20418002988610948\n",
      "Epoch: 47 Loss: 0.19499637771930015\n",
      "Epoch: 48 Loss: 0.1956560547862734\n",
      "Epoch: 49 Loss: 0.23604366396154677\n",
      "Epoch: 50 Loss: 0.20908711850643158\n",
      "Epoch: 51 Loss: 0.1908025113599641\n",
      "Epoch: 52 Loss: 0.20257110467978887\n",
      "Epoch: 53 Loss: 0.2011209066425051\n",
      "Epoch: 54 Loss: 0.17266059161296912\n",
      "Epoch: 55 Loss: 0.18074276724031993\n",
      "Epoch: 56 Loss: 0.3455091044306755\n",
      "Epoch: 57 Loss: 0.19221627765468188\n",
      "Epoch: 58 Loss: 0.1964363945381982\n",
      "Epoch: 59 Loss: 0.1845072523823806\n",
      "Epoch: 60 Loss: 0.1996005688394819\n",
      "Epoch: 61 Loss: 0.1728251124066966\n",
      "Epoch: 62 Loss: 0.18397694187504904\n",
      "Epoch: 63 Loss: 0.16068258988005774\n",
      "Epoch: 64 Loss: 0.14973156939127616\n",
      "Epoch: 65 Loss: 0.1547932199069432\n",
      "Epoch: 66 Loss: 0.1866583036524909\n",
      "Epoch: 67 Loss: 0.2640734144619533\n",
      "Epoch: 68 Loss: 0.15898761791842325\n",
      "Epoch: 69 Loss: 0.15004744593586242\n",
      "Epoch: 70 Loss: 0.14237761874392163\n",
      "Epoch: 71 Loss: 0.15045172295400075\n",
      "Epoch: 72 Loss: 0.13399012865764753\n",
      "Epoch: 73 Loss: 0.13575171945350512\n",
      "Epoch: 74 Loss: 0.1281865117156745\n",
      "Epoch: 75 Loss: 0.12750200667817677\n",
      "Epoch: 76 Loss: 0.13074198844177382\n",
      "Epoch: 77 Loss: 0.12327664847751814\n",
      "Epoch: 78 Loss: 0.12390822065728051\n",
      "Epoch: 79 Loss: 0.12191045044788293\n",
      "Epoch: 80 Loss: 0.16877106151410512\n",
      "Epoch: 81 Loss: 0.19201170865978515\n",
      "Epoch: 82 Loss: 0.14649462600105576\n",
      "Epoch: 83 Loss: 0.12338545013751302\n",
      "Epoch: 84 Loss: 0.11964296256857258\n",
      "Epoch: 85 Loss: 0.11524044429617268\n",
      "Epoch: 86 Loss: 0.1114928387105465\n",
      "Epoch: 87 Loss: 0.11117480216281754\n",
      "Epoch: 88 Loss: 0.12317466735839844\n",
      "Epoch: 89 Loss: 0.14277223178318568\n",
      "Epoch: 90 Loss: 0.14265493835721696\n",
      "Epoch: 91 Loss: 0.1531310219849859\n",
      "Epoch: 92 Loss: 0.1200408690742084\n",
      "Epoch: 93 Loss: 0.11508984863758087\n",
      "Epoch: 94 Loss: 0.131525525024959\n",
      "Epoch: 95 Loss: 0.10276889907462257\n",
      "Epoch: 96 Loss: 0.11198942682572774\n",
      "Epoch: 97 Loss: 0.13972067194325583\n",
      "Epoch: 98 Loss: 0.09881333581038884\n",
      "Epoch: 99 Loss: 0.1041775814124516\n"
     ]
    }
   ],
   "source": [
    "# Train the neural network\n",
    "for epoch in range(100):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(dataloader):\n",
    "        inputs, labels = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    print(f'Epoch: {epoch} Loss: {running_loss / len(dataloader)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions using the trained neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted classes: [1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on multiple samples\n",
    "predicted_classes = []\n",
    "for i in range(features_normalized.shape[0]):\n",
    "    sample = features_normalized[i]\n",
    "    output = net(sample)\n",
    "    _, predicted_class = torch.max(output, 0)\n",
    "    predicted_classes.append(predicted_class.item())\n",
    "\n",
    "print(f'Predicted classes: {predicted_classes}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
