{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-elaborazione dei dati\n",
    "\n",
    "In questa sezione, viene eseguita la pre-elaborazione dei dati per la successiva addestramento della rete neurale. Il processo di pre-elaborazione comprende la lettura dei dati dal file CSV, la normalizzazione delle feature utilizzando la tecnica di MinMaxScaler e la suddivisione del dataset in set di addestramento, convalida e test.\n",
    "\n",
    "- **Lettura dei dati**: I dati vengono letti dal file CSV utilizzando la libreria `pandas`. Il file `parkinsons.csv` contiene le informazioni sulle caratteristiche dei pazienti con Parkinson.\n",
    "\n",
    "- **Separazione delle feature e delle etichette**: Le feature del dataset sono ottenute rimuovendo le colonne \"name\" e \"status\" dal dataframe. Le etichette corrispondono alla colonna \"status\".\n",
    "\n",
    "- **Normalizzazione delle feature**: Per garantire che tutte le feature abbiano la stessa scala, viene utilizzato il `MinMaxScaler` di scikit-learn per normalizzare le feature nel range [0, 1].\n",
    "\n",
    "- **Suddivisione dei dati**: Il dataset normalizzato viene suddiviso in tre set: addestramento, convalida e test. Questo viene fatto utilizzando la funzione `train_test_split` di scikit-learn. In questo caso, il 70% dei dati viene utilizzato per l'addestramento, il 15% per la convalida e il restante 15% per il test.\n",
    "\n",
    "- **Salvataggio dei dati**: I set di dati risultanti vengono salvati in file separati utilizzando la funzione `np.save` di NumPy. Vengono salvati i seguenti file:\n",
    "    - `train_features.npy`: feature del set di addestramento\n",
    "    - `train_labels.npy`: etichette del set di addestramento\n",
    "    - `val_features.npy`: feature del set di convalida\n",
    "    - `val_labels.npy`: etichette del set di convalida\n",
    "    - `test_features.npy`: feature del set di test\n",
    "    - `test_labels.npy`: etichette del set di test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read in the data from the CSV file\n",
    "data = pd.read_csv('Dataset/parkinsons.csv')\n",
    "\n",
    "# Separate the input features and the output class\n",
    "features = data.drop(['name', 'status'], axis=1)\n",
    "labels = data['status']\n",
    "\n",
    "# Create a MinMaxScaler object\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler on the input features\n",
    "scaler.fit(features)\n",
    "\n",
    "# Transform the input features using the scaler\n",
    "features_normalized = scaler.transform(features)\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features_normalized, labels, test_size=0.3, random_state=42)\n",
    "val_features, test_features, val_labels, test_labels = train_test_split(test_features, test_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "# Save the pre-processed data to files\n",
    "np.save('Pre_Processed_Data/train_features.npy', train_features)\n",
    "np.save('Pre_Processed_Data/train_labels.npy', train_labels)\n",
    "np.save('Pre_Processed_Data/val_features.npy', val_features)\n",
    "np.save('Pre_Processed_Data/val_labels.npy', val_labels)\n",
    "np.save('Pre_Processed_Data/test_features.npy', test_features)\n",
    "np.save('Pre_Processed_Data/test_labels.npy', test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
